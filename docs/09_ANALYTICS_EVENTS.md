# 09_ANALYTICS_EVENTS.md

## Aethos – Behavioral Signal & Analytics Specification

---

# I. Purpose

Analytics in Aethos are not growth-hacking telemetry.

They serve three institutional functions:

1. Validate hypothesis that timing + journaling creates insight.
2. Measure retention through reflective engagement.
3. Quantify behavioral correlation without making predictive claims.

This system must be:

- Deterministic
- Privacy-respecting
- Structured
- Statistically interpretable
- Legally defensible

---

# II. Analytics Philosophy

Aethos does NOT track:

- Scroll depth for manipulation
- Addictive engagement loops
- Behavioral nudging experiments

Aethos DOES track:

- Timing exposure
- Reflective journaling frequency
- Mood variance relative to symbolic activation

We measure pattern awareness, not addiction.

---

# III. Core Event Taxonomy

All analytics events fall into four categories:

1. System Computation Events
2. User Behavioral Events
3. Reflective Journal Events
4. Derived Insight Events

---

# IV. System Computation Events

These are generated automatically.

## Event: `salience_computed`

Payload:
- date
- salience_score
- top_activation_ids (array)
- hard_soft_ratio
- angular_activation_count

Purpose:
Track distribution of timing intensity over time.

---

## Event: `activation_generated`

Payload:
- transit_planet
- natal_point
- aspect_type
- orb
- house
- weight_score
- activation_id

Purpose:
Allow correlation engine to map specific activation categories.

---

# V. User Behavioral Events

These measure engagement quality.

## Event: `today_view_loaded`

Payload:
- timestamp
- salience_score
- activation_count

Purpose:
Track exposure frequency.

---

## Event: `activation_detail_opened`

Payload:
- activation_id
- dwell_time_seconds

Purpose:
Measure insight exploration depth.

---

## Event: `weekly_summary_viewed`

Payload:
- timestamp
- mood_avg_week
- hard_soft_ratio_week

Purpose:
Track pattern review engagement.

---

# VI. Reflective Journal Events

This is the core behavioral dataset.

## Event: `journal_entry_created`

Payload:
- mood (1–10)
- energy (1–10)
- stress (1–10)
- tag_count
- word_count
- linked_activation_ids
- timestamp_local
- timestamp_utc

Derived fields (computed, not user-entered):
- active_salience_score_at_entry
- hard_soft_ratio_at_entry
- dominant_planet_at_entry
- dominant_house_at_entry

Purpose:
Enable structured correlation without claiming causation.

---

# VII. Derived Insight Events

Generated by correlation engine.

## Event: `weekly_pattern_generated`

Payload:
- avg_mood
- avg_stress
- most_activated_planet
- most_volatile_house
- correlation_strength_score

Purpose:
Quantify insight density.

---

## Event: `monthly_pattern_generated`

Payload:
- mood_variance
- stress_variance
- activation_density
- correlation_delta_vs_last_month

Purpose:
Track longitudinal pattern awareness.

---

# VIII. Correlation Model (Statistical Layer)

V1 uses simple descriptive statistics:

- Mean mood by activation category
- Standard deviation by hard vs soft aspect days
- Pearson correlation (bounded, labeled descriptive only)
- Activation frequency histogram

No predictive modeling.
No forecasting.
No recommendation engine.

Output language must always include:

> "Observed association. Not causal inference."

---

# IX. Insight Density Metric

Define:

Insight Density Score (IDS) =

(
    # Journal entries linked to activations
    / total journal entries
) 
×
(
    # Distinct activation categories referenced
)

This metric measures whether users are actively connecting experience to timing structure.

This becomes a key internal KPI.

---

# X. Retention Quality Metrics

We measure:

1. Journaling Compliance Rate
   ≥3 entries per week target.

2. Pattern Review Rate
   Weekly summary views / weekly active users.

3. Activation Engagement Depth
   Avg dwell time >20 seconds per activation detail.

4. Correlation Clarity Score
   User-rated (1–10) “Did this week help you notice patterns?”

These are leading indicators of retention.

---

# XI. Data Privacy Model

Analytics storage rules:

- No journal content used for marketing.
- No cross-user aggregation unless anonymized.
- Birth data separated from analytics logs.
- All logs user-deletable.

Retention period:
- Raw analytics logs: 12 months.
- Aggregated metrics: indefinite (anonymized).

---

# XII. Data Schema Overview

analytics_events table:

- event_id (UUID)
- user_id (UUID)
- event_type (string)
- payload (JSONB)
- created_at (UTC)

journal_entries table:

- entry_id (UUID)
- user_id (UUID)
- mood
- energy
- stress
- text_encrypted
- created_at
- linked_activation_ids (array)

correlation_summaries table:

- summary_id
- user_id
- time_period (week/month)
- metrics (JSONB)
- generated_at

---

# XIII. Institutional Credibility Guardrails

The analytics system must never:

- Claim predictive accuracy.
- Claim psychological diagnosis.
- Suggest behavioral prescriptions.
- Present correlation as fate.

All correlation outputs must use:

"Observed pattern during this period."

Never:

"This caused..."

---

# XIV. Phase 2 Beta Analytics Targets

At 50–100 users:

We aim to observe:

- ≥50% journaling compliance.
- ≥60% weekly summary engagement.
- ≥0.3 correlation strength (descriptive).
- ≥8 clarity score average.

If analytics show low IDS (<0.2), UX must simplify.

If IDS high but retention low → pricing or positioning issue.

---

# XV. Expansion Hooks (Post Validation)

Future upgrades (not in V1):

- Cross-user anonymized aggregate benchmarks.
- Activation cluster heatmaps.
- Behavioral tagging taxonomy.
- Multi-system cross-correlation (HD + Western).
- ML-assisted clustering (optional).

Only after V1 retention validated.

---

# XVI. Definition of Analytics Success

Analytics succeed when:

- Users demonstrate measurable pattern recognition.
- Journaling connects to timing events.
- Correlation language remains legally defensible.
- Data remains ethically minimal.

Analytics are not a growth engine.

They are the epistemic backbone of Aethos.
